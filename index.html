<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects - Smail Ait Bouhsain, Rachid Alami, Thierry Simeon">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="We propose a feasibility-enabled multi-robot TAMP algorithm for complex manipulation tasks, extending feasibility prediction to mesh-shaped objects and multi-robot settings and demonstrating improved performance over non-informed baselines.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="task and motion planning, TAMP, 3D environments, action feasibility prediction, deep neural networks, robotics, scene representation, manipulation planning, geometric planning, machine learning, artificial intelligence, multi-robot systems">
  <!-- TODO: List all authors -->
  <meta name="author" content="Smail Ait Bouhsain, Rachid Alami, Thierry Simeon">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="LAAS-CNRS">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects - Smail Ait Bouhsain, Rachid Alami, Thierry Simeon">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="We propose a feasibility-enabled multi-robot TAMP algorithm for complex manipulation tasks, extending feasibility prediction to mesh-shaped objects and multi-robot settings and demonstrating improved performance over non-informed baselines.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://smail8.github.io/agfpnet-extension/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://github.com/Smail8/agfpnet-extension/tree/master/static/images/poster.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects - Smail Ait Bouhsain, Rachid Alami, Thierry Simeon - Research Preview">
  <meta property="article:published_time" content="2024-10-14T00:00:00.000Z">
  <meta property="article:author" content="Smail Ait Bouhsain">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="task and motion planning">
  <meta property="article:tag" content="action feasibility prediction">
  <meta property="article:tag" content="robotics">
  <meta property="article:tag" content="deep learning">
  <meta property="article:tag" content="multi-robot systems">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@LaasCNRS">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@Sm1Le8B">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="We propose a feasibility-enabled multi-robot TAMP algorithm for complex manipulation tasks, extending feasibility prediction to mesh-shaped objects and multi-robot settings and demonstrating improved performance over non-informed baselines.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://github.com/Smail8/agfpnet-extension/tree/master/static/images/poster.png">
  <meta name="twitter:image:alt" content="Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects">
  <meta name="citation_author" content="Ait Bouhsain, Smail">
  <meta name="citation_author" content="Alami, Rachid">
  <meta name="citation_author" content="Siméon, Thierry">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)">
  <meta name="citation_pdf_url" content="https://github.com/Smail8/agfpnet-extension/tree/master/static/pdfs/paper.pdf">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects - Ait Bouhsain, Smail, Alami, Rachid, Siméon, Thierry | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/panda_icon.png">
  <link rel="apple-touch-icon" href="static/images/panda_icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects",
    "description": "This paper presents a novel approach to enhance task and motion planning by incorporating action feasibility prediction, specifically for multi-robot manipulation of realistic objects.",
    "author": [
      {
        "@type": "Person",
        "name": "Ait Bouhsain, Smail",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      },
      {
        "@type": "Person",
        "name": "Alami, Rachid",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      },
      {
        "@type": "Person",
        "name": "Siméon, Thierry",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      }
    ],
    "datePublished": "2024-10-14",
    "publisher": {
      "@type": "Organization",
      "name": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)"
    },
    "url": "https://smail8.github.io/agfpnet-extension/",
    "image": "https://github.com/Smail8/agfpnet-extension/tree/master/static/images/poster.png",
    "keywords": [
      "task and motion planning",
      "TAMP",
      "3D environments",
      "action feasibility prediction",
      "deep neural networks",
      "robotics",
      "scene representation",
      "manipulation planning",
      "geometric planning",
      "machine learning",
      "artificial intelligence",
      "multi-robot systems"
    ],
    "abstract": "The hybrid discrete/continuous nature of task and motion planning (TAMP) results often in a combinatorial explosion. This challenge is even more pronounced in multi-robot TAMP problems due to the increase in dimensionality of the action space. Previous works use action feasibility prediction as a heuristic to accelerate TAMP. However, these methods are limited to box-shaped objects and specific single or dual robot settings. In this paper, we propose a feasibility-enabled multi-robot TAMP algorithm capable of tackling complex multi-robot manipulation problems. Also, we expand on our previous work on action and grasp feasibility prediction [1] by extending its use to mesh-shaped objects. We demonstrate the performance of our method compared to a non feasibility-informed baseline, and show its ability to handle TAMP problems requiring the collaboration of multiple robots.",
    "citation": "@inproceedings{ait2024extending,
      title={Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects},
      author={Ait Bouhsain, Smail and Alami, Rachid and Simeon, Thierry},
      booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
      pages={10318--10325},
      year={2024},
      organization={IEEE}
    }",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://smail8.github.io/agfpnet-extension/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "AI for Robotics"
      },
      {
        "@type": "Thing", 
        "name": "Machine Learning"
      },
      {
        "@type": "Thing", 
        "name": "Task and Motion Planning"
      },
      {
        "@type": "Thing", 
        "name": "Deep Learning"
      },
      {
        "@type": "Thing", 
        "name": "Multi-Robot Systems"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "LAAS-CNRS",
    "url": "https://laas.fr",
    "logo": "https://github.com/Smail8/agfpnet-extension/tree/master/static/images/laas_logo.png",
    "sameAs": [
      "https://twitter.com/LaasCNRS",
      "https://github.com/Smail8/agfpnet-extension"
    ]
  }
  </script>
</head>

<body>
  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://openreview.net/pdf?id=ajxAJ8GUX4" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Learning Geometric Reasoning Networks for Robot Task and Motion Planning</h5>
            <p>We present Geometric Reasoning Networks (GRN), a graph neural network-based model for predicting action and grasp feasibility in Task and Motion Planning (TAMP). GRN reduces reliance on geometric planners by incorporating interpretability mechanisms such as inverse kinematics feasibility prediction and grasp obstruction estimation, enabling efficient and explainable planning in complex 3D environments.</p>
            <span class="work-venue">The Thirteenth International Conference on Learning Representations (ICLR 2025)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10341257" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning</h5>
            <p>We propose AGFP-Net, a multi-task neural network that predicts action feasibility and grasp type feasibility, significantly improving task and motion planning (TAMP) by reducing geometric planning time and solving more complex problems.</p>
            <span class="work-venue">2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10161114" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments</h5>
            <p>We introduce a novel approach for Task and Motion Planning (TAMP) in 3D environments, combining an efficient 3D scene representation with a deep neural network to predict action feasibility, significantly reducing geometric planning time by up to 90% on complex problems.</p>
            <span class="work-venue">2023 IEEE International Conference on Robotics and Automation (ICRA)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <!-- TODO: Replace with your paper title -->
              <h1 class="title is-1 publication-title">Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects</h1>
              <div class="is-size-5 publication-authors">
                <!-- TODO: Replace with your paper authors and their personal links -->
                <span class="author-block"><a href="https://smail8.github.io" target="_blank">Smail Ait Bouhsain</a>,</span>
                <span class="author-block"><a href="https://www.laas.fr/en/homepages/rachid/" target="_blank">Rachid Alami</a>,</span>
                <span class="author-block"><a href="https://www.laas.fr/fr/annuaire/29" target="_blank">Thierry Siméon</a></span>
              </div>

              <div class="is-size-5 publication-authors">
                <!-- TODO: Replace with your institution and conference/journal info -->
                <span class="author-block">LAAS-CNRS<br>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10802307" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- TODO: Add your supplementary material PDF or remove this section -->
                  <span class="link-block">
                    <a href="static/images/poster.png" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-photo-video"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/smail8/agfpnet-extension" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="https://laas.hal.science/hal-04636503v1/document" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-hal"></i>
                      </span>
                      <span>HAL</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <!-- TODO: Replace with your teaser video -->
          <iframe width="100%" height="500px" src="https://www.youtube.com/embed/lQ7irSnAmr4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>      
          <!-- TODO: Replace with your video description -->
          <!-- TODO: Replace with your video description -->
          <h2 class="subtitle has-text-centered">
            Our method addresses the combinatorial challenges of task and motion planning (TAMP) in multi-robot systems by introducing a feasibility-enabled TAMP algorithm. Leveraging advancements in action and grasp feasibility prediction, our approach extends these predictions to mesh-shaped objects and multi-robot settings, enabling the symbolic planner to focus on geometrically feasible solutions. This significantly reduces planning time and enhances the system's ability to solve complex multi-robot manipulation tasks requiring collaboration.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <!-- TODO: Replace with your paper abstract -->
              <p>
                The hybrid discrete/continuous nature of task and motion planning (TAMP) results often in a combinatorial explosion. This challenge is even more pronounced in multi-robot TAMP problems due to the increase in dimensionality of the action space. Previous works use action feasibility prediction as a heuristic to accelerate TAMP. However, these methods are limited to box-shaped objects and specific single or dual robot settings. In this paper, we propose a feasibility-enabled multi-robot TAMP algorithm capable of tackling complex multi-robot manipulation problems. Also, we expand on our previous work on action and grasp feasibility prediction [1] by extending its use to mesh-shaped objects. We demonstrate the performance of our method compared to a non feasibility-informed baseline, and show its ability to handle TAMP problems requiring the collaboration of multiple robots..
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Neural Network Image -->
    <section class="section hero is-small">
      <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
        <h2 class="title is-3">Proposed Model</h2>
        <figure class="image">
          <!-- TODO: Replace with the actual image path -->
          <img src="static/images/model1.png" alt="Diagram of AGFPNet">
        </figure>
        <div style="margin-top: 20px;"></div> <!-- Added vertical space -->
        <p class="subtitle">
          The action and grasp feasibility prediction neural network architecture (<strong>AGFPNet</strong>).
        </p>
        <div style="margin-top: 50px;"></div> <!-- Added vertical space -->
        <figure class="image">
          <!-- TODO: Replace with the actual image path -->
          <img src="static/images/model2.png" alt="Diagram of AGFPNet's extension to multi-robot settings">
        </figure>
        <div style="margin-top: 20px;"></div> <!-- Added vertical space -->
        <p class="subtitle">
          A visualization of the proposed extension of AGFPNet to multi-robot settings.
        </p>
        <div style="margin-top: 50px;"></div> <!-- Added vertical space -->
        <div class="columns is-centered">
          <div class="column is-half">
            <figure class="image">
              <!-- TODO: Replace with the actual image path -->
              <img src="static/images/grasps.png" alt="Diagram of AGFPNet's extension to mesh-shaped objects">
            </figure>
          </div>
          <div class="column is-half is-flex is-align-items-center">
            <figure class="image">
              <!-- TODO: Replace with the actual image path -->
              <img src="static/images/grasps2.png" alt="Diagram of AGFPNet's extension to mesh-shaped objects">
            </figure>
          </div>
        </div>
        <div style="margin-top: 20px;"></div> <!-- Added vertical space -->
        <p class="subtitle">
          A visualization of the proposed extension of grasp representation to mesh-shaped objects.
        </p>
        </div>
      </div>
      </div>
    </section>
    <!-- End Neural Network Image -->

    <!-- Benchmarks Section -->
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Benchmarks</h2>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <!-- TODO: Replace with the actual image path -->
                <img src="static/images/access.png" alt="Access">
              </figure>
                <p class="subtitle"><strong>Access problem:</strong> A single robot has to move a meat can. A number of mesh objects are however blocking access to it, which requires removing all blocking objects to access the wanted one, before returning them to their initial pose.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <!-- TODO: Replace with the actual image path -->
                <img src="static/images/sort.png" alt="Sort Benchmark">
              </figure>
                <p class="subtitle"><strong>Sort problem:</strong> A dual-robot task where objects must be sorted onto two pre-occupied tables. The challenge involves finding feasible placements on narrow surfaces, with each robot restricted to accessing only one table, and a subset of the objects only.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <!-- TODO: Replace with the actual image path -->
                <img src="static/images/clear.png" alt="Clear Benchmark">
              </figure>
              <p class="subtitle"><strong>Clear problem:</strong> Two large objects (in red) span over the intersection region of two robots’ workspaces, rendering Pass actions infeasible. The robots have to first clear the intersection region before moving a set of objects from one table to another.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <!-- TODO: Replace with the actual image path -->
                <img src="static/images/longswap.gif" alt="Longswap Benchmark">
              </figure>
              <p class="subtitle"><strong>Longswap problem:</strong> Three sequential robots have to collaborate to swap the placements of 4 objects. The intersection regions between robots’ workspaces are, however, partially blocked by a set of obstacles.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <!-- TODO: Replace with the actual image path -->
                <img src="static/images/middleman3.png" alt="Middleman3 Benchmark">
              </figure>
              <p class="subtitle"><strong>Middleman3 problem:</strong> Three robots form a triangle such that there is an intersection between every pair of robots' workspaces. One of the intersection regions is blocked by a fixed obstacle, forcing the robots to perform two $Pass$ actions via a middleman robot to move three objects from one counter to the other.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <!-- TODO: Replace with the actual image path -->
                <img src="static/images/middleman5.png" alt="Middleman5 Benchmark">
              </figure>
                <p class="subtitle"><strong>Middleman5 problem:</strong> Four symbolic action sequences allow each one of four objects to be moved from a shelf to a table, however three of them are blocked by fixed obstacles. The planner must find the only geometrically feasible sequence of robots exchanges to solve the problem.</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Benchmarks Section -->

    <!-- Results Section -->
    <section class="section hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Results</h2>
          <div class="columns is-centered">
            <div class="column is-full has-text-centered">
              <figure class="image">
                <img src="static/images/results.png" alt="Combined Results">
              </figure>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Results Section -->

    <!-- Visualizations Section -->
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Visualizations</h2>
          <div class="columns is-centered">
            <div class="column is-full has-text-centered">
              <p class="subtitle">Plan execution visualizations for each problem.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <!-- First GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/access.gif" alt="Visualization 1">
              </figure>
              <p class="subtitle"><strong>Access Problem</strong></p>
            </div>
          </div>
          <div class="columns is-centered" style="margin-top: 2rem;">
            <!-- Second GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/sort.gif" alt="Visualization 2">
              </figure>
              <p class="subtitle"><strong>Sort Problem</strong></p>
            </div>
            <!-- Third GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/clear.gif" alt="Visualization 3">
              </figure>
              <p class="subtitle"><strong>Clear Problem</strong></p>
            </div>
          </div>
          <div class="columns is-centered" style="margin-top: 2rem;">
            <!-- Fourth GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/longswap.gif" alt="Visualization 4">
              </figure>
              <p class="subtitle"><strong>Long-swap Problem</strong></p>
            </div>
            <!-- Fifth GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/middleman.gif" alt="Visualization 5">
              </figure>
              <p class="subtitle"><strong>Middleman3 Problem</strong></p>
            </div>
          </div>
          <div class="columns is-centered" style="margin-top: 2rem;">
            
            <!-- Sixth GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/maze.gif" alt="Visualization 6">
              </figure>
              <p class="subtitle"><strong>Middleman5 Problem</strong></p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Visualizations Section -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code">
          <code>
            @inproceedings{ait2024extending,
              title={Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects},
              author={Ait Bouhsain, Smail and Alami, Rachid and Simeon, Thierry},
              booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
              pages={10318--10325},
              year={2024},
              organization={IEEE}
            }
          </code>
        </pre>
      </div>
    </section>
    <!--End BibTex citation -->
  </main>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>
</html>
